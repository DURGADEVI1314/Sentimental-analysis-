{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2_Ivn4Tjv0M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import word tokenize\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download(\")\n",
        "\n",
        "# Load data\n",
        "\n",
        "car_reviews = pd.read_csv(\"/content/Scraped_Car_Review_tesla.csv\")\n",
        "\n",
        "# Data preprocessing\n",
        "\n",
        "def preprocess text(text):\n",
        "\n",
        "text re.sub(r'\\d+', \", text) # Remove numbers\n",
        "\n",
        "text text lower() # Convert to lowercase\n",
        "\n",
        "text = re.sub(r'\\s+','', text) # Remove extra whitespaces\n",
        "\n",
        "text = re.sub(r<[^>]+>', \", text) # Remove HTML tags\n",
        "\n",
        "text = re.sub(r\\s+', '', text) # Remove extra whitespaces againreturn text\n",
        "\n",
        "car_reviews = car_reviews.rename(columns={'review':'Review'})\n",
        "\n",
        "#Tokenization, lemmatization, and stopword removal\n",
        "\n",
        "stop_words = set(stopwords words('english'))\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tokenize_lemmatize(text):\n",
        "\n",
        "tokens word tokenize(text)\n",
        "\n",
        "tokens = [lemmatizer. lemmatize(word) for word in tokens if word not in\n",
        "\n",
        "stop_words]\n",
        "\n",
        "return tokens\n",
        "\n",
        "car_reviews['tokens'] = car_reviews['Review'].apply(tokenize_lemmatize)\n",
        "\n",
        "#Sentiment analysis using TextBlob\n",
        "\n",
        "def get sentiment(text):\n",
        "\n",
        "analysis TextBlob(text)\n",
        "\n",
        "return 'positive' if analysis sentiment polarity > 0 else 'negative'\n",
        "\n",
        "car_reviews['sentiment'] = car_reviews['Review'].apply(get_sentiment)\n",
        "\n",
        "#Topic modeling using Latent Dirichlet Allocation (LDA)\n",
        "\n",
        "def lda_topic_modeling(reviews, num_topics=5):\n",
        "\n",
        "vectorizer =TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "\n",
        "tfidf vectorizer.fit transform(reviews)Ida_model LatentDirichletAllocation(n_components=num_topics,\n",
        "\n",
        "max_iter=10, learning_method='online', random_state=42)\n",
        "\n",
        "Ida_model, fit(tfidf)\n",
        "\n",
        "return lda model, vectorizer\n",
        "\n",
        "# Perform topic modeling on positive and negative reviews separately\n",
        "\n",
        "positive_reviews = car_reviews[car_reviews['sentiment'] 'positive']['Review']\n",
        "\n",
        "negative_reviews = car_reviews[car_reviews['sentiment'] = 'negative']['Review']\n",
        "\n",
        "positive_lda_model, positive_vectorizer = Ida_topic_modeling(positive_reviews)\n",
        "\n",
        "negative_Ida_model, negative_vectorizer = Ida topic modeling(negative reviews)\n",
        "\n",
        "# Display topics for positive and negative reviews\n",
        "\n",
        "print(\"Topics for Positive Reviews:\")\n",
        "\n",
        "for index, topic in enumerate(positive_Ida_model.components):\n",
        "\n",
        "print(f\"Topic (index+1}:\")\n",
        "\n",
        "top words indices = topic argsort()[-10:]\n",
        "\n",
        "top_words = [positive_vectorizer.get_feature_names_out()[i] for i in\n",
        "\n",
        "top_words_indices]\n",
        "\n",
        "print(top_words)\n",
        "\n",
        "print(\"\\nTopics for Negative Reviews:\")\n",
        "\n",
        "for index, topic in enumerate(negative_Ida_model.components_):\n",
        "\n",
        "print(f'Topic {index+1}:\")top_words_indices = topic.argsort()[-10:]\n",
        "\n",
        "top_words = [negative_vectorizer.get_feature_names_out()[i] for i in\n",
        "\n",
        "top_words_indices]\n",
        "\n",
        "print(top_words)"
      ]
    }
  ]
}